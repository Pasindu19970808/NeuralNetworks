{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only one previous context, it works. However it quickly blows up when there you nee more context.\n",
    "\n",
    "With three character context, we have 27*27*27 character posibilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement a multilayer perceptron to predict the next character in a sequence. Bengio et al. 2003"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are building a character level language model.\n",
    "\n",
    "1) Every character is associated with a 30 dimensional feature vector. \n",
    "2) In the beginning these words are initialized randomly\n",
    "3) Tune the embeddings using back propagation\n",
    "4) Words that have similar meanings will end up in similar part of space and others are far away.\n",
    "5) Use a MLP network to predict the next word by using the previous words. \n",
    "6) Maximize the log likelihood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we have a sentence \"A dog was running in a ____\", but this never appeared in the training data, hence we are out of distribution. We dont have fundamentally any reason to suspect what might come next. \n",
    "\n",
    "But if we have seen similar phrases. Hence we can use the embeddings that was learnt for similar words to generalize. \n",
    "\n",
    "Through the embedding space we can generalize to novel scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
